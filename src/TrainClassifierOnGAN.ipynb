{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from dcgan_discriminator import Discriminator\n",
    "from dcgan_discriminator_multipleOut import Discriminator_MO\n",
    "from dcgan_classifier import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 128\n",
    "lr = 0.0001#2\n",
    "train_epoch = 100\n",
    "\n",
    "# data_loader\n",
    "img_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either run bellow for MNIST or next for CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "from SparseMNIST import SparseMNIST\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SparseMNIST('data', 0.01, train=True, download=True, transform=transform, showAll=False),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR 10\n",
    "from SparseCIFAR import SparseCIFAR\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,) * 3, std=(0.5,) * 3)\n",
    "])\n",
    "train_loader =  torch.utils.data.DataLoader(\n",
    "    SparseCIFAR('data', 4000/50000, train=True, download=True, transform=transform, showAll=False),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader =  torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10('data', train=False, download=True, transform=transform),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "#print(len(datasets.CIFAR10('data', train=True, download=True, transform=transform)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_classifier(model_name, conv_resolution=128, channels=1, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True):\n",
    "    # MNIST - Load Pretrained\n",
    "    D = Discriminator(conv_resolution=conv_resolution, channels=channels, \n",
    "                      mbl_size=mbl_size, train_classes=train_classes)\n",
    "    D = torch.load(model_name)\n",
    "    #D.weight_init(mean=0.0, std=0.02) # From scratch\n",
    "\n",
    "    # MNIST - Save and build one with Multiple outputs\n",
    "    torch.save(D.state_dict(),'tmp.pt')\n",
    "    D_MO = Discriminator_MO(conv_resolution=conv_resolution, channels=channels, \n",
    "                            mbl_size=mbl_size, train_classes=train_classes, \n",
    "                            freeze=freezePretrained)\n",
    "    #D_MO = Discriminator_MO(conv_resolution=128, channels=1, mbl_size=0, train_classes=False, freeze=False)\n",
    "    D_MO.load_state_dict(torch.load('tmp.pt'))\n",
    "    D_MO.eval()\n",
    "    D_MO.cuda()\n",
    "\n",
    "    # MNIST - Build classifier ontop\n",
    "    C = Classifier(D_MO,d=conv_resolution)\n",
    "    C.weight_init(mean=0.0, std=0.02)\n",
    "    C.cuda()\n",
    "    C.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar_classifier(model_name, conv_resolution=100, channels=3, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True):\n",
    "    #CIFAR - Load Pretrained\n",
    "    D = Discriminator(conv_resolution=conv_resolution, channels=channels,\n",
    "                      mbl_size=mbl_size, train_classes=train_classes)\n",
    "    D = torch.load(model_name) # If pretrained\n",
    "    #D.weight_init(mean=0.0, std=0.02) # From scratch\n",
    "\n",
    "    # CIFAR - Save and build one with Multiple outputs\n",
    "    torch.save(D.state_dict(),'tmp.pt')\n",
    "    D_MO = Discriminator_MO(conv_resolution=conv_resolution, channels=channels, \n",
    "                            mbl_size=mbl_size, train_classes=train_classes, \n",
    "                            freeze=freezePretrained)\n",
    "    #D_MO = Discriminator_MO(conv_resolution=100, channels=3, mbl_size=0, train_classes=False, freeze=freezePretrained)\n",
    "    D_MO.load_state_dict(torch.load('tmp.pt'))\n",
    "    D_MO.eval()\n",
    "    D_MO.cuda()\n",
    "\n",
    "    # CIFAR - Build classifier ontop\n",
    "    C = Classifier(D_MO,d=conv_resolution)\n",
    "    C.weight_init(mean=0.0, std=0.02)\n",
    "    C.cuda()\n",
    "    C.train()\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains a classifier\n",
    "def train(C, train_loader, val_loader, train_epoch = 100):\n",
    "    CE_loss = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    C_optimizer = optim.Adam(C.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    train_hist = {}\n",
    "    train_hist['C_losses'] = []\n",
    "    train_hist['C_acc'] = []\n",
    "    train_hist['per_epoch_ptimes'] = []\n",
    "    train_hist['total_ptime'] = []\n",
    "\n",
    "    num_iter = 0\n",
    "    loss_info = False #Print Train Loss\n",
    "    eval_nth = 5\n",
    "    best_acc = 0\n",
    "\n",
    "    print('training start!')\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(train_epoch):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        C_losses =[]\n",
    "\n",
    "        for x_, y_real_label_ in train_loader:\n",
    "            # train classifier\n",
    "            C.zero_grad()\n",
    "            x_ = Variable(x_.cuda())\n",
    "            y_real_label_ = Variable(y_real_label_.cuda())\n",
    "\n",
    "            C_result = C(x_).squeeze()\n",
    "            C_real_loss = CE_loss(C_result, y_real_label_)\n",
    "\n",
    "            C_real_loss.backward()\n",
    "            C_optimizer.step()\n",
    "\n",
    "            train_hist['C_losses'].append(C_real_loss.data[0])\n",
    "            C_losses.append(C_real_loss.data[0])\n",
    "            if(loss_info):\n",
    "                print(C_real_loss.data[0])\n",
    "\n",
    "            num_iter += 1\n",
    "\n",
    "        C.eval()\n",
    "\n",
    "        val_scores = []\n",
    "\n",
    "        if epoch % eval_nth == 0 or epoch == train_epoch-1:\n",
    "            print('Validate ...')\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = Variable(inputs), Variable(targets)\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                outputs = C(inputs).squeeze()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                scores = np.mean((preds == targets).data.cpu().numpy())\n",
    "                val_scores.append(scores)\n",
    "\n",
    "            val_acc = np.mean(val_scores)\n",
    "            train_hist['C_acc'].append(val_acc)\n",
    "\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "\n",
    "        C.train()\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "        print('[%d/%d] - ptime: %.2f, loss_c: %.3f, acc_c: %.3f' % ((epoch + 1), \n",
    "            train_epoch, per_epoch_ptime, \n",
    "            torch.mean(torch.FloatTensor(C_losses)), val_acc))\n",
    "\n",
    "        #p = 'MNIST_DCGAN_results/Random_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
    "        #fixed_p = 'MNIST_DCGAN_results/Fixed_results/MNIST_DCGAN_' + str(epoch + 1) + '.png'\n",
    "        #show_result((epoch+1), save=True, path=p, isFix=False)\n",
    "        #show_result((epoch+1), save=True, path=fixed_p, isFix=True)\n",
    "        train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_ptime = end_time - start_time\n",
    "    train_hist['total_ptime'].append(total_ptime)\n",
    "\n",
    "    print(\"Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_ptimes'])), train_epoch, total_ptime))\n",
    "    print(\"Best Accuaracy: {}\".format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/dl4cv-64/src/dcgan_classifier.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  c = F.softmax(self.conv5_c(c))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate ...\n",
      "[1/100] - ptime: 19.58, loss_c: 2.167, acc_c: 0.354\n",
      "[2/100] - ptime: 8.89, loss_c: 2.067, acc_c: 0.354\n",
      "[3/100] - ptime: 8.91, loss_c: 2.026, acc_c: 0.354\n",
      "[4/100] - ptime: 8.93, loss_c: 1.994, acc_c: 0.354\n",
      "[5/100] - ptime: 8.93, loss_c: 1.961, acc_c: 0.354\n",
      "Validate ...\n",
      "[6/100] - ptime: 15.29, loss_c: 1.942, acc_c: 0.455\n",
      "[7/100] - ptime: 8.98, loss_c: 1.915, acc_c: 0.455\n",
      "[8/100] - ptime: 8.98, loss_c: 1.892, acc_c: 0.455\n",
      "[9/100] - ptime: 8.96, loss_c: 1.866, acc_c: 0.455\n",
      "[10/100] - ptime: 8.98, loss_c: 1.847, acc_c: 0.455\n",
      "Validate ...\n",
      "[11/100] - ptime: 15.35, loss_c: 1.821, acc_c: 0.489\n",
      "[12/100] - ptime: 8.97, loss_c: 1.803, acc_c: 0.489\n",
      "[13/100] - ptime: 8.97, loss_c: 1.783, acc_c: 0.489\n",
      "[14/100] - ptime: 8.97, loss_c: 1.761, acc_c: 0.489\n",
      "[15/100] - ptime: 8.98, loss_c: 1.745, acc_c: 0.489\n",
      "Validate ...\n",
      "[16/100] - ptime: 15.34, loss_c: 1.737, acc_c: 0.504\n",
      "[17/100] - ptime: 8.96, loss_c: 1.714, acc_c: 0.504\n",
      "[18/100] - ptime: 8.97, loss_c: 1.705, acc_c: 0.504\n",
      "[19/100] - ptime: 8.98, loss_c: 1.687, acc_c: 0.504\n",
      "[20/100] - ptime: 8.96, loss_c: 1.674, acc_c: 0.504\n",
      "Validate ...\n",
      "[21/100] - ptime: 15.36, loss_c: 1.662, acc_c: 0.514\n",
      "[22/100] - ptime: 8.97, loss_c: 1.644, acc_c: 0.514\n",
      "[23/100] - ptime: 8.99, loss_c: 1.635, acc_c: 0.514\n",
      "[24/100] - ptime: 8.97, loss_c: 1.632, acc_c: 0.514\n",
      "[25/100] - ptime: 8.96, loss_c: 1.615, acc_c: 0.514\n",
      "Validate ...\n",
      "[26/100] - ptime: 15.35, loss_c: 1.607, acc_c: 0.516\n",
      "[27/100] - ptime: 9.00, loss_c: 1.600, acc_c: 0.516\n",
      "[28/100] - ptime: 8.98, loss_c: 1.593, acc_c: 0.516\n",
      "[29/100] - ptime: 8.98, loss_c: 1.587, acc_c: 0.516\n",
      "[30/100] - ptime: 8.97, loss_c: 1.582, acc_c: 0.516\n",
      "Validate ...\n",
      "[31/100] - ptime: 15.37, loss_c: 1.572, acc_c: 0.527\n"
     ]
    }
   ],
   "source": [
    "C = cifar_classifier('cifar_fm_models/d_0.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_models/d_1.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_models/d_4.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_models/d_9.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_models/d_19.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=0, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_mbd_models/d_0.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=8, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_mbd_models/d_1.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=8, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_mbd_models/d_2.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=8, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_mbd_models/d_4.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=8, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_mbd_models/d_9.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=8, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = cifar_classifier('cifar_fm_mbd_models/d_19.model', conv_resolution=100, channels=3, \n",
    "                     mbl_size=8, train_classes=False, \n",
    "                     freezePretrained = True)\n",
    "train(C, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
