Feature matching introduces another loss function for the Generator to minimize. Additionally to maximizing the missclassification rate of its outputs the generator tries to meet the expectation of a feature map f(x) within the discriminator. With stochastic optimization this results in the additional loss term ||Mean(f(x)) - Mean(f(G(z)))||_2^2 for the generator, where x is the feature map from a batch of real images, z is the random latent space variable for the generator and f is the last hidden featuremap of the discriminator.

(This is motivated by the observation that the Discriminator is searching for the most discriminative features to tell real and fake apart. Minimizing the distance between real and fake feature maps should therefore result in a more convincing Generator. [OpenAI] observed that this approach lead to stronger semi-supervised learning but weaker subjective image quality.)
